---
title: 'Scorecards'
description: 'Define how the AI evaluates your reps conversations'
---

<iframe
  width="100%"
  height="400"
  src="https://www.loom.com/embed/1d0e50cb5116438d891866970ad1fc55?sid=497fc2f7-32ff-4e59-bc12-55f4ca3ea0c8"
  frameborder="0"
  webkitallowfullscreen
  mozallowfullscreen
  allowfullscreen
></iframe>

## What are Scorecards?

Scorecards provide the AI with a specific rubric to evaluate conversations. The AI will analyze the conversation transcript and score it based on the criteria you define.

## Building a Scorecard

### Question Types

You can create different types of evaluation criteria:

- **Yes/No Questions**: Simple binary evaluation
- **Compound Questions**: Combination of multiple yes/no criteria
- **Open-ended Questions**: For gathering general feedback
- **Range Questions**: Score on a scale of 1-10

### Criteria Components

Each scoring criterion includes:

- Title
- Question type
- Specific question for the AI to evaluate
- Weight (importance in the overall score)

<Note>
  The AI evaluates the conversation transcript against each criterion to generate the final score.
</Note>

## Example Structure

A typical scorecard might evaluate:

- Call to action
- Building urgency
- Introduction
- Benefit explanation

<Tip>
  Use the "Distribute Weights" button to automatically balance the scoring criteria evenly.
</Tip>

## Reusability

Criteria can be:

- Saved and reused across different scorecards
- Mixed and matched for different types of conversations
- Adjusted with different weights for various scenarios
